
@article{falkSignificanceTestsHard1995,
  title = {Significance {{Tests Die Hard}}: {{The Amazing Persistence}} of a {{Probabilistic Misconception}}},
  shorttitle = {Significance {{Tests Die Hard}}},
  author = {Falk, Ruma and Greenbaum, Charles W.},
  year = {1995},
  month = feb,
  journal = {Theory \& Psychology},
  volume = {5},
  number = {1},
  pages = {75--98},
  issn = {0959-3543, 1461-7447},
  doi = {10.1177/0959354395051004},
  abstract = {We present a critique showing the flawed logical structure of statistical significance tests. We then attempt to analyze why, in spite of this faulty reasoning, the use of significance tests persists. We identify the illusion of probabilistic proof by contradiction as a central stumbling block, because it is based on a misleading generalization of reasoning from logic to inference under uncertainty. We present new data from a student sample and examples from the psychological literature showing the strength and prevalence of this illusion. We identify some intrinsic cognitive mechanisms (similarity to modus tollens reasoning; verbal ambiguity in describing the meaning of significance tests; and the need to rule out chance findings) and extrinsic social pressures which help to maintain the illusion. We conclude by mentioning some alternative methods for presenting and analyzing psychological data, none of which can be considered the ultimate method.},
  langid = {english}
}

@article{fidlerWhyFiguresError2009,
  title = {{Why Figures with Error Bars Should Replace \emph{p} Values: Some Conceptual Arguments and Empirical Demonstrations}},
  shorttitle = {{Why Figures with Error Bars Should Replace \emph{p} Values}},
  author = {Fidler, Fiona and Loftus, Geoffrey R.},
  year = {2009},
  month = jan,
  journal = {Zeitschrift f\"ur Psychologie / Journal of Psychology},
  volume = {217},
  number = {1},
  pages = {27--37},
  issn = {0044-3409},
  doi = {10.1027/0044-3409.217.1.27},
  abstract = {Null-hypothesis significance testing (NHST) is the primary means by which data are analyzed and conclusions made, particularly in the social sciences, but in other sciences as well (notably ecology and economics). Despite this supremacy however, numerous problems exist with NHST as a means of interpreting and understanding data. These problems have been articulated by various observers over the years, but are being taken seriously by researchers only slowly, if at all, as evidenced by the continuing emphasis on NHST in statistics classes, statistics textbooks, editorial policies and, of course, the day-to-day practices reported in empirical articles themselves ( Cumming et al., 2007 ). Over the past several decades, observers have suggested a simpler approach \textendash{} plotting the data with appropriate confidence intervals (CIs) around relevant sample statistics \textendash{} to supplement or take the place of hypothesis testing. This article addresses these issues.},
  langid = {german}
}

@article{gigerenzerMindlessStatistics2004,
  title = {Mindless Statistics},
  author = {Gigerenzer, Gerd},
  year = {2004},
  month = nov,
  journal = {The Journal of Socio-Economics},
  volume = {33},
  number = {5},
  pages = {587--606},
  issn = {10535357},
  doi = {10.1016/j.socec.2004.09.033},
  langid = {english}
}

@article{goodmanDirtyDozenTwelve2008,
  title = {A {{Dirty Dozen}}: {{Twelve P-Value Misconceptions}}},
  shorttitle = {A {{Dirty Dozen}}},
  author = {Goodman, Steven},
  year = {2008},
  month = jul,
  journal = {Seminars in Hematology},
  volume = {45},
  number = {3},
  pages = {135--140},
  issn = {00371963},
  doi = {10.1053/j.seminhematol.2008.04.003},
  langid = {english}
}

@article{hallerMisinterpretationsSignificanceProblem2002,
  title = {Misinterpretations of {{Significance}}: {{A Problem Students Share}} with {{Their Teachers}}?},
  author = {Haller, Heiko and Krauss, Stefan},
  year = {2002},
  journal = {Methods of Psychological Research Online},
  volume = {7},
  number = {1},
  abstract = {The use of significance tests in science has been debated from the invention of these tests until the present time. Apart from theoretical critiques on their appropriateness for evaluating scientific hypotheses, significance tests also receive criticism for inviting misinterpretations. We presented six common misinterpretations to psychologists who work in German universities and found out that they are still surprisingly widespread \textendash{} even among instructors who teach statistics to psychology students. Although these misinterpretations are well documented among students, until now there has been little research on pedagogical methods to remove them. Rather, they are considered ``hard facts'' that are impervious to correction. We discuss the roots of these misinterpretations and propose a pedagogical concept to teach significance tests, which involves explaining the meaning of statistical significance in an appropriate way.},
  file = {/home/neonjahr/Zotero/storage/HNAATK76/Haller and Krauss - Misinterpretations of Significance A Problem Stud.pdf}
}

@article{heldReverseBayesAnalysisTwo2013,
  title = {Reverse-{{Bayes}} Analysis of Two Common Misinterpretations of Significance Tests},
  author = {Held, Leonhard},
  year = {2013},
  month = apr,
  journal = {Clinical Trials (London, England)},
  volume = {10},
  number = {2},
  pages = {236--242},
  issn = {1740-7753},
  doi = {10.1177/1740774512468807},
  abstract = {BACKGROUND: Misunderstanding of significance tests and P values is widespread in clinical research and elsewhere. PURPOSE: To assess the implications of two common mistakes in the interpretation of statistical significance tests. The first one is the misinterpretation of the type I error rate as the expected proportion of false-positive results among all those called significant, also known as the false-positive report probability (FPRP). The second is the misinterpretation of a P value as (posterior) probability of the null hypothesis. METHODS: A reverse-Bayes approach is used to calculate a lower bound on the proportion of truly effective treatments that would ensure the FPRP to be equal or below the type I error rate. A reverse-Bayes approach using minimum Bayes factors (BFs) yields upper bounds on the prior probability of the null hypothesis that would justify the interpretation of the P value as the posterior probability of the null hypothesis. RESULTS: In a typical clinical trials setting, more than 50\% of the treatments need to be truly effective to justify equality of the type I error rate and the FPRP. To interpret the P value as posterior probability, the difference between the corresponding prior probability and the P value cannot exceed 12.4 percentage points. LIMITATIONS: The first analysis requires that the (one-sided) type I error rate is smaller than the type II error rate. The second result is valid under different scenarios describing how to transform P values to minimum BFs. CONCLUSIONS: The two misinterpretations imply strong and often unrealistic assumptions on the prior proportion or probability of truly effective treatments.},
  langid = {english},
  pmid = {23329516},
  keywords = {Bayes Theorem,Data Interpretation; Statistical,False Positive Reactions,Humans,Research Design}
}

@article{hoekstraRobustMisinterpretationConfidence2014,
  title = {Robust Misinterpretation of Confidence Intervals},
  author = {Hoekstra, Rink and Morey, Richard D. and Rouder, Jeffrey N. and Wagenmakers, Eric-Jan},
  year = {2014},
  month = oct,
  journal = {Psychonomic Bulletin \& Review},
  volume = {21},
  number = {5},
  pages = {1157--1164},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-013-0572-3},
  langid = {english}
}

@article{knottnerusEthicsSampleSize2001,
  title = {The Ethics of Sample Size: Two-Sided Testing and One-Sided Thinking.},
  author = {Knottnerus, J. A. and Bouter, L. M.},
  year = {2001},
  month = feb,
  journal = {Journal of clinical epidemiology},
  volume = {54},
  number = {2},
  pages = {109--110},
  address = {{United States}},
  issn = {0895-4356},
  doi = {10.1016/s0895-4356(00)00276-6},
  langid = {english},
  pmid = {11166523},
  keywords = {*Data Interpretation; Statistical,*Ethics; Medical,*Sample Size,Bias,Biomedical and Behavioral Research,Clinical Trials as Topic/*standards,Evidence-Based Medicine,Humans,Philosophy; Medical,Research Design/*standards}
}

@article{moreyFallacyPlacingConfidence2016,
  title = {The Fallacy of Placing Confidence in Confidence Intervals},
  author = {Morey, Richard D. and Hoekstra, Rink and Rouder, Jeffrey N. and Lee, Michael D. and Wagenmakers, Eric-Jan},
  year = {2016},
  month = feb,
  journal = {Psychonomic Bulletin \& Review},
  volume = {23},
  number = {1},
  pages = {103--123},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-015-0947-8},
  langid = {english},
  file = {/home/neonjahr/Zotero/storage/ISWVWITV/Morey et al. - 2016 - The fallacy of placing confidence in confidence in.pdf}
}

@article{muffRewritingResultsSections2022a,
  title = {Rewriting Results Sections in the Language of Evidence},
  author = {Muff, Stefanie and Nilsen, Erlend B. and O'Hara, Robert B. and Nater, Chlo{\'e} R.},
  year = {2022},
  month = mar,
  journal = {Trends in Ecology \& Evolution},
  volume = {37},
  number = {3},
  pages = {203--210},
  issn = {01695347},
  doi = {10.1016/j.tree.2021.10.009},
  langid = {english},
  file = {/home/neonjahr/Zotero/storage/YSZQ75EI/Muff et al. - 2022 - Rewriting results sections in the language of evid.pdf}
}

@article{murtaughDefenseValues2014,
  title = {In Defense of {{{\emph{P}}}} Values},
  author = {Murtaugh, Paul A.},
  year = {2014},
  month = mar,
  journal = {Ecology},
  volume = {95},
  number = {3},
  pages = {611--617},
  issn = {0012-9658},
  doi = {10.1890/13-0590.1},
  langid = {english},
  file = {/home/neonjahr/Zotero/storage/XUA2Z7YI/Murtaugh - 2014 - In defense of P values.pdf}
}

@book{oakesStatisticalInferenceCommentary1986,
  title = {Statistical Inference: A Commentary for the Social and Behavioural Sciences},
  shorttitle = {Statistical Inference},
  author = {Oakes, Michael W.},
  year = {1986},
  publisher = {{Wiley}},
  address = {{Chichester ; New York}},
  isbn = {978-0-471-10443-8},
  lccn = {HA29 .O18 1986},
  keywords = {Probabilities,Psychometrics,Social sciences,Statistical methods}
}

@book{royallStatisticalEvidenceLikelihood1997,
  title = {Statistical Evidence: A Likelihood Paradigm},
  shorttitle = {Statistical Evidence},
  author = {Royall, Richard M.},
  year = {1997},
  series = {Monographs on Statistics and Applied Probability},
  edition = {1st ed},
  number = {71},
  publisher = {{Chapman \& Hall}},
  address = {{London ; New York}},
  isbn = {978-0-412-04411-3},
  lccn = {QA276.8 .R69 1997},
  keywords = {Estimation theory,Mathematical statistics,Probabilities}
}

@article{schmidtStatisticalSignificanceTesting1996,
  title = {Statistical Significance Testing and Cumulative Knowledge in Psychology: {{Implications}} for Training of Researchers.},
  shorttitle = {Statistical Significance Testing and Cumulative Knowledge in Psychology},
  author = {Schmidt, Frank L.},
  year = {1996},
  journal = {Psychological Methods},
  volume = {1},
  number = {2},
  pages = {115--129},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/1082-989X.1.2.115},
  langid = {english}
}

@article{stephensInformationTheoryHypothesis2005,
  title = {Information Theory and Hypothesis Testing: A Call for Pluralism},
  shorttitle = {Information Theory and Hypothesis Testing},
  author = {Stephens, Philip A. and Buskirk, Steven W. and Hayward, Gregory D. and Martinez Del Rio, Carlos},
  year = {2005},
  month = feb,
  journal = {Journal of Applied Ecology},
  volume = {42},
  number = {1},
  pages = {4--12},
  issn = {0021-8901, 1365-2664},
  doi = {10.1111/j.1365-2664.2005.01002.x},
  langid = {english},
  file = {/home/neonjahr/Zotero/storage/U6GM3K2Z/Stephens et al. - 2005 - Information theory and hypothesis testing a call .pdf}
}

@article{tendeiroReviewIssuesNull2019,
  title = {A Review of Issues about Null Hypothesis {{Bayesian}} Testing},
  author = {Tendeiro, Jorge N. and Kiers, Henk A. L.},
  year = {2019},
  month = dec,
  journal = {Psychological Methods},
  volume = {24},
  number = {6},
  pages = {774--795},
  issn = {1939-1463},
  doi = {10.1037/met0000221},
  abstract = {Null hypothesis significance testing (NHST) has been under scrutiny for decades. The literature shows overwhelming evidence of a large range of problems affecting NHST. One of the proposed alternatives to NHST is using Bayes factors instead of p values. Here we denote the method of using Bayes factors to test point null models as "null hypothesis Bayesian testing" (NHBT). In this article we offer a wide overview of potential issues (limitations or sources of misinterpretation) with NHBT which is currently missing in the literature. We illustrate many of the shortcomings of NHBT by means of reproducible examples. The article concludes with a discussion of NHBT in particular and testing in general. In particular, we argue that posterior model probabilities should be given more emphasis than Bayes factors, because only the former provide direct answers to the most common research questions under consideration. (PsycINFO Database Record (c) 2019 APA, all rights reserved).},
  langid = {english},
  pmid = {31094544},
  keywords = {Data Interpretation; Statistical,Humans,Models; Statistical,Probability,Research Design},
  file = {/home/neonjahr/Zotero/storage/5BVMPWSR/Tendeiro and Kiers - 2019 - A review of issues about null hypothesis Bayesian .pdf}
}

@article{vanravenzwaaijAdvantagesMasqueradingIssues2021,
  title = {Advantages Masquerading as "Issues" in {{Bayesian}} Hypothesis Testing: {{A}} Commentary on {{Tendeiro}} and {{Kiers}} (2019)},
  shorttitle = {Advantages Masquerading as "Issues" in {{Bayesian}} Hypothesis Testing},
  author = {{van Ravenzwaaij}, Don and Wagenmakers, Eric-Jan},
  year = {2021},
  month = dec,
  journal = {Psychological Methods},
  issn = {1939-1463},
  doi = {10.1037/met0000415},
  abstract = {Tendeiro and Kiers (2019) provide a detailed and scholarly critique of Null Hypothesis Bayesian Testing (NHBT) and its central component-the Bayes factor-that allows researchers to update knowledge and quantify statistical evidence. Tendeiro and Kiers conclude that NHBT constitutes an improvement over frequentist p-values, but primarily elaborate on a list of 11 "issues" of NHBT. We believe that several issues identified by Tendeiro and Kiers are of central importance for elucidating the complementary roles of hypothesis testing versus parameter estimation and for appreciating the virtue of statistical thinking over conducting statistical rituals. But although we agree with many of their thoughtful recommendations, we believe that Tendeiro and Kiers are overly pessimistic, and that several of their "issues" with NHBT may in fact be conceived as pronounced advantages. We illustrate our arguments with simple, concrete examples and end with a critical discussion of one of the recommendations by Tendeiro and Kiers, which is that "estimation of the full posterior distribution offers a more complete picture" than a Bayes factor hypothesis test. (PsycInfo Database Record (c) 2021 APA, all rights reserved).},
  langid = {english},
  pmid = {34881956},
  file = {/home/neonjahr/Zotero/storage/IMEF8GXT/van Ravenzwaaij and Wagenmakers - 2021 - Advantages masquerading as issues in Bayesian hy.pdf}
}


